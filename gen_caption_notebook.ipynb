{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Molecular Captioning with Qwen3-0.6B\n",
    "\n",
    "Two-stage training pipeline:\n",
    "1. **Stage 1 (Alignment)**: Train projector to align GNN embeddings with LLM text space\n",
    "2. **Stage 2 (SFT)**: Fine-tune projector + LoRA adapters for caption generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": "# Cell 1.5: Google Colab Setup\ntry:\n    from google.colab import drive\n    import os\n    print(\"Running on Google Colab. Setting up repository...\")\n\n    # Clone the repository if not already present\n    REPO_DIR = \"/content/altegrad_kaggle\"\n    REPO_URL = \"https://github.com/AxENSRennes/altegrad_kaggle.git\"\n    BRANCH = \"axel\"\n\n    if not os.path.exists(REPO_DIR):\n        print(f\"Cloning {REPO_URL} (branch: {BRANCH})...\")\n        !git lfs install\n        !git clone -b {BRANCH} {REPO_URL} {REPO_DIR}\n        print(\"Repository cloned successfully.\")\n    else:\n        print(f\"Repository already exists at {REPO_DIR}\")\n        %cd {REPO_DIR}\n        !git pull origin {BRANCH}\n        !git lfs pull\n\n    %cd {REPO_DIR}\n    print(f\"Working directory: {os.getcwd()}\")\n\nexcept ImportError:\n    print(\"Not running on Google Colab (ImportError).\")\nexcept Exception as e:\n    print(f\"Error during Colab setup: {e}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Install Dependencies\n",
    "!pip install -q transformers>=4.36 peft bitsandbytes accelerate wandb rich nltk torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 2: Imports and Path Setup\nimport sys\nimport os\n\n# Auto-detect environment\nif os.path.exists(\"/kaggle/input/mol-caption-code\"):\n    sys.path.insert(0, \"/kaggle/input/mol-caption-code\")\n    print(\"Running on Kaggle\")\nelif os.path.exists(\"/content/altegrad_kaggle/mol-caption-code\"):\n    sys.path.insert(0, \"/content/altegrad_kaggle/mol-caption-code\")\n    print(\"Running on Colab\")\nelse:\n    sys.path.insert(0, \"./mol-caption-code\")\n    print(\"Running locally\")\n\nimport torch\nfrom config import get_config\nfrom model_wrapper import create_model\nfrom train_stage1 import train_stage1\nfrom train_stage2 import train_stage2\nfrom inference import run_inference\nfrom metrics import compute_metrics\nfrom report import print_training_report\nfrom utils import set_seed, WandBLogger\n\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Configure Experiment Mode\n",
    "# Choose mode: \"quick\" (5min test), \"medium\" (1h), \"full\" (9h)\n",
    "config = get_config(\n",
    "    mode=\"quick\",  # Change to \"medium\" or \"full\" for longer training\n",
    "    use_wandb=False,  # Set to True to enable W&B logging\n",
    ")\n",
    "\n",
    "print(f\"Experiment mode: {config.experiment_mode}\")\n",
    "print(f\"Stage 1 epochs: {config.stage1_epochs}\")\n",
    "print(f\"Stage 2 epochs: {config.stage2_epochs}\")\n",
    "print(f\"Train subset: {config.train_subset or 'all'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 4: W&B Initialization (Optional)\nif config.use_wandb:\n    import wandb\n    wandb.login()\n    logger = WandBLogger(enabled=True)\n    logger.init(config.wandb_project, config, tags=[config.experiment_mode])\n    print(\"W&B initialized\")\nelse:\n    logger = None\n    print(\"W&B disabled - set config.use_wandb=True to enable\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Set Seed & Create Model\n",
    "set_seed(config.seed)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "model = create_model(config, device)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 6: Stage 1 Training (Alignment)\nprint(\"=\" * 50)\nprint(\"STAGE 1: Alignment Training\")\nprint(\"=\" * 50)\n\nstage1_metrics = train_stage1(model, config, logger=logger)\nprint_training_report(\"Stage 1\", stage1_metrics, config)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 7: Stage 2 Training (SFT)\nprint(\"=\" * 50)\nprint(\"STAGE 2: Supervised Fine-Tuning\")\nprint(\"=\" * 50)\n\nstage2_metrics = train_stage2(model, config, load_stage1=True, logger=logger)\nprint_training_report(\"Stage 2\", stage2_metrics, config)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Generate Submission (Full Mode)\n",
    "if config.experiment_mode == \"full\":\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Generating Submission\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    results = run_inference(config)\n",
    "    print(f\"Submission saved to: {config.submission_path}\")\n",
    "else:\n",
    "    print(\"Skipping submission generation (not in full mode)\")\n",
    "    print(\"Run with mode='full' for full training and submission\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 9: Cleanup\nif logger:\n    logger.finish()\n    print(\"W&B run finished\")\n\nprint(\"Done!\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}